{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"PPO-delta\"\n",
    "checkpoints = 50000\n",
    "model_checkpoints = \"best_model_\" + str(checkpoints) # Speicify the model file to load. Model \"ppo_ryu_2500000_steps_updated\" is capable of beating the final stage (Bison) of the game.\n",
    "\n",
    "\n",
    "RENDERING = True    # Whether to render the game screen.\n",
    "RESET_ROUND = True  # Whether to reset the round when fight is over. \n",
    "\n",
    "RANDOM_ACTION = False\n",
    "NUM_EPISODES = 100 # Make sure NUM_EPISODES >= 3 if you set RESET_ROUND to False to see the whole final stage game.\n",
    "MODEL_DIR = \"trained_models_\" + model_name +\"/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "\n",
    "if RENDERING:\n",
    "    virtual_display = Display(visible=0, size=(1400, 900))\n",
    "    virtual_display.start()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "\n",
    "import retro\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import the sb3 monitor for logging \n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "# Import the vec wrappers to vectorize and frame stack\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "\n",
    "from street_fighter_custom_wrapper import StreetFighterCustomWrapper\n",
    "\n",
    "env = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis',\n",
    "                state=\"Champion.Level12.RyuVsBison\", \n",
    "                use_restricted_actions=retro.Actions.FILTERED)\n",
    "env = StreetFighterCustomWrapper(env)\n",
    "# env = Monitor(env, LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not RANDOM_ACTION:\n",
    "    model = PPO.load(os.path.join(MODEL_DIR, model_checkpoints))\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "num_episodes = NUM_EPISODES\n",
    "episode_reward_sum = 0\n",
    "num_victory = 0\n",
    "\n",
    "print(\"\\nFighting Begins!\\n\")\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    done = False\n",
    "    \n",
    "    if RESET_ROUND:\n",
    "        obs = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    if RENDERING:\n",
    "        img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "    while not done:\n",
    "        timestamp = time.time()\n",
    "\n",
    "        if RANDOM_ACTION:\n",
    "            # sample action from action space\n",
    "            # obs, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "            # test specified action\n",
    "            # button_combos [[0, 16, 32], [0, 64, 128], [0, 1, 2, 3, 256, 257, 512, 513, 1024, 1026, 1536, 2048, 2304, 2560]]\n",
    "            # buttons ['B', 'A', 'MODE', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'C', 'Y', 'X', 'Z']\n",
    "            test_action = [0,0,0,0,1,0,0,0,0,0,0,0]\n",
    "            obs, reward, done, info = env.step(test_action)\n",
    "        else:\n",
    "            action, _states = model.predict(obs)\n",
    "            # print(action)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward != 0:\n",
    "            total_reward += reward\n",
    "            # print(\"Reward: {:.3f}, playerHP: {}, enemyHP:{}\".format(reward, info['agent_hp'], info['enemy_hp']))\n",
    "        \n",
    "        # done should be returned by env.step() when the game is over\n",
    "        # if info['enemy_hp'] < 0 or info['agent_hp'] < 0:\n",
    "        #     done = True\n",
    "\n",
    "        if RENDERING:\n",
    "            img.set_data(env.render(mode='rgb_array'))\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "    if info['enemy_hp'] < 0:\n",
    "        print(_, \"Victory!\")\n",
    "        num_victory += 1\n",
    "    else:\n",
    "        print(_, \"Lose...\")\n",
    "\n",
    "    # print(\"Total reward: {}\\n\".format(total_reward))\n",
    "    episode_reward_sum += total_reward\n",
    "\n",
    "    if not RESET_ROUND:\n",
    "        while info['enemy_hp'] < 0 or info['agent_hp'] < 0:\n",
    "        # Inter scene transition. Do nothing.\n",
    "            obs, reward, done, info = env.step([0] * 12)\n",
    "            if RENDERING:\n",
    "                env.render(mode='rgb_array')\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(\"\\nFighting Ends!\\n\")\n",
    "print(model_checkpoints)\n",
    "print(\"Winning rate: {}\".format(1.0 * num_victory / num_episodes))\n",
    "if RANDOM_ACTION:\n",
    "    print(\"Average reward for random action: {}\".format(episode_reward_sum/num_episodes))\n",
    "else:\n",
    "    print(\"Average reward for {}: {}\".format(model_checkpoints, episode_reward_sum/num_episodes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
